{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3d7842",
   "metadata": {},
   "source": [
    "<html style=\"background-color: white\">\n",
    "    <head style=\"background-color: white\">\n",
    "        <div style=\"position: relative; width: 1084px; margin: 50px auto; padding: 15px auto;\">\n",
    "            <figure style=\"max-width: 500px; float:left; padding: 10px; margin: 10px;\">\n",
    "                <a href=\"https://decide4ai.com/\" target=\"_blank\"><img style=\"padding: px; margin: 0;\" src=\"./recursos/imagenes/FULLCOLOR.png\" alt=\"logo decide\"></a>\n",
    "            </figure>\n",
    "            <figure style=\"max-width: 500px; float:left; padding: 10px; margin: 32px 10px 10px 10px;\">\n",
    "                <a href=\"https://t3chfest.es/2023/\" target=\"_blank\"><img style=\"padding: 0; margin: 0;\" src=\"./recursos/imagenes/t3f_logo.png\" alt=\"logo t3ch festival\"></a>\n",
    "            </figure>\n",
    "        </div>\n",
    "        <div style=\"position: relative; border-top:3px solid #002060; border-bottom:3px solid #002060; margin-top: 300px; height: 96px; margin-right: auto; margin-left: auto;\">\n",
    "            <a href=\"./u3c1.ipynb\" target=\"_blank\"><img style=\"float: left; height: 64px; width: 76px;  margin:1% 1% 1% 7%;\" src=\"./recursos/imagenes/ICON-FULLCOLOR-ROT.png\" alt=\"icono decide4ai rotado\"></a>\n",
    "            <h1 style=\"color: #002060; text-align: center; margin: 2% 0; padding: 0; width: 70%; float: left;\">\n",
    "                <a href=\"./u3.ipynb\" style=\"color: #002060\">Unidad 3: Motores de recomendación de filtrado colaborativo</a><br><a href=\"./indice.ipynb\" style=\"font-size: 10px; color: #bf27b8\">Volver al índice</a>\n",
    "            </h1>\n",
    "            <a href=\"./u3c3.ipynb\" target=\"_blank\"><img style=\"float: left; height: 64px; width: 76px; margin:1% auto 1% 1%;\" src=\"./recursos/imagenes/ICON-FULLCOLOR.png\" alt=\"icono decide4ai\"></a>\n",
    "        </div>\n",
    "        <ol style=\"text-align: left; list-style-type: none; margin-top: 75px;\">\n",
    "            <li style=\"margin: 20px 0;\"><h5><a style=\"color: #f47b4c\" href=\"./u3c1.ipynb\" target=\"_blank\"> Motores de recomendación de filtrado colaborativo basados en memoria.</a></h5></li>\n",
    "            <li style=\"margin: 20px 0;\"><h5><a style=\"color: #fc5100\" href=\"./u3c2.ipynb\" target=\"_blank\"><strong>Motores de recomendación de filtrado colaborativo basados en modelos.</strong></a></h5></li>\n",
    "            <li style=\"margin: 20px 0;\"><h5><a style=\"color: #f47b4c\" href=\"./u3c3.ipynb\" target=\"_blank\"> Motores de recomendación de filtrado colaborativo basados en redes neuronales.</a></h5></li>\n",
    "        </ol>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1 style=\"color: #fc5100; margin-top: 100px;\">Motores de recomendación de filtrado colaborativo basados en modelos</h1>\n",
    "        <p style=\"font-size: 18px; color: #002060;\">\n",
    "        Esta familia de motores de recomendación utilizan un enfoque que incorpora conceptos de Machine Learning. Básicamente, se crean modelos a partir de la <strong>matriz de interacción</strong> para luego realizar predicciones. Existen muchos tipos de sistemas de recomendación basados en modelos (Singular Value Decomposition, Bayesian Matrix Factorization, NNs, Autoencoders, etc.), pero aquí veremos únicamente el <strong>SVD</strong>.\n",
    "        </p>\n",
    "        <p style=\"font-size: 18px; color: #002060;\">\n",
    "            Pero, antes de entrar más en el algoritmo de <em>Singular Value Decomposition</em> popular gracias a Netflix, vamos a entender que conceptos de machine learning se aplican en este tipo de algoritmos.<br>\n",
    "            Vamos a partir de una matriz de interacción <em>user-item</em> que vamos a denominar $R$ que tiene $M$ usuarios y $N$ productos. Esta matriz $R$ puede ser veces que ha comprado un producto, veces que ha visto una pelicula, rating de un libro, etc. La idea es descomponer esta matriz $R$ en el producto de dos sub matrices más pequeñas que puedan reconstruir la matriz original. Estas matrices más pequeñas las vamos a denominar $U$, que tiene $M$ filas y $K$ columnas, y $V$ que tiene $K$ filas y $N$ columnas. Dado que $U$ contiene las mismas filas que usuarios hay, esta matriz tiene información sobre los usuarios únicamente. Mientras que $V$ que tiene las mismas columnas que productos hay, contiene la información de los productos.\n",
    "        </p>\n",
    "        <p style=\"font-size: 18px; color: #002060;\">\n",
    "            Pero, ¿que es $K$? K es la dimensión del espacio en el que se reduce. Es decir, la matriz de usuarios $U$ describe a los usuarios en un espacio de variables latentes de tamaño $K$. Mientras que la matriz de productos $V$ describe a los productos en un espacio de variables latentes $K$.\n",
    "        </p>\n",
    "        <div style=\"position:relative; width: 858px; margin: 50px auto; padding: 15px auto;\">\n",
    "            <figure style=\"width: 858px; height: 450px; padding: 0 40px; margin: 0; text-align: center; color: #002060;\">\n",
    "                <img style=\"width: 850px; height: 450px; padding: 0; margin: 0;\" src=\"./recursos/imagenes/matrix_factorization.png\">\n",
    "                <figcaption>Fundamentos de la factorización matricial.</figcaption>\n",
    "            </figure>\n",
    "        </div>\n",
    "        <p style=\"font-size: 18px; color: #002060;\">\n",
    "            Esto reduce el problema de calcular un rating simplemente al producto matricial de una fila ($i$) de la matriz $U$ por un item ($j$) de la matriz $V$. Es decir, si definimos $R_{i, j}$ como el rating (real) que el usuario $i$ le da al producto $j$, ese rating se puede <u>aproximar</u> a través de $\\hat{R}_{i, j} = \\sum_{k=1}^{K}U_{i, k}\\cdot V_{k, j}$. Y aquí es donde el machine learning aparece. ¿qué valores tienen las matrices $U$ y $V$? pues esto se hace minimizándo el error cuadrático de los ratings reales frente a los calculados a través de esas dos matrices. Es decir $err_{i, j}^2 = (R_{i, j} - \\sum_{k=1}^{K}U_{i, k}\\cdot V_{k, j})^2$ minimizándo ese error con un descenso del gradiente, por ejemplo, obtendríamos dos matrices $U$ y $V$ de menor dimensionalidad cuya multiplicación nos daría el rating que una persona da a un artículo dado.\n",
    "        </p>\n",
    "        <p style=\"font-size: 18px; color: #002060;\">\n",
    "            Esto tiene dos ventajas:\n",
    "        </p>\n",
    "        <ul style=\"text-align: left; font-size: 18px; color: #002060;\">\n",
    "            <li style=\"margin: 20px 0;\">Las matrices resultantes son más pequeñas que la matriz inicial, por lo que se disminuye la carga computacional.</li>\n",
    "            <li style=\"margin: 20px 0;\">Para recomendar se calculan las similitudes sobre un espacio latente de $K$ dimensiones que contiene información que a priori no tiene porque ser trivial de usuarios o productos.</li>\n",
    "        </ul>\n",
    "        <h2 style=\"color: #f47b4c; margin-top: 100px;\">Singular Value Decomposition</h2>\n",
    "        <p style=\"font-size: 18px; color: #002060;\">\n",
    "            Anteriormente se ha dicho que la factorización matricial se puede hacer minimizándo el error entre el valor real y la aproximación. Sin embargo en el ágebra lineal hay métodos numéricos, que permiten descomponer una matriz en una o varias matrices más pequeñas. La descomposición LU o QR son ampliamente usadas en muchas áreas de las ciencias. Sin embargo, hay una que intrínsecamente tiene asociada una importancia a cada nueva variable que se crea de las submatrices. Y es la descomposición en valores singulares.\n",
    "        </p>\n",
    "        <div style=\"position:relative; width: 1058px; margin: 50px auto; padding: 15px auto;\">\n",
    "            <figure style=\"width: 1058px; height: 450px; padding: 0 40px; margin: 0; text-align: center; color: #002060;\">\n",
    "                <img style=\"width: 1050px; height: 450px; padding: 0; margin: 0;\" src=\"./recursos/imagenes/svd.png\">\n",
    "                <figcaption><em>Singular Value Decomposition</em>.</figcaption>\n",
    "            </figure>\n",
    "        </div>\n",
    "        <p style=\"font-size: 18px; color: #002060;\">\n",
    "            El proceso es el siguiente, la matriz $U_{M, M}$ es una matriz de usuarios que son autovectores de la matriz $R_{M, N}\\cdot R_{N, M}$, estos autovectores tienen asociados unos autovalores que son los componentes singulares y están dados en la matriz $\\sigma_{M, N}$ que es una matriz diagonal. Finalmente se tiene la matriz $V_{N, N}$ que se obtiene de resolver la ecuación matricial dada en la figura anterior. Esta última tiene información de los productos.<br>\n",
    "            Y, ¿qué es $k$? $k$ es la elección de las top $k$ variables de la descomposición matricial asociada a los valores singurales más altos. Esta es la importancia que tiene esta descomposición, que se puede elegir un espacio latente menor al original que mantenga la mayor carga de información.<br> Existen varias maneras de saber como encontrar ese valor de $k$ optimo, tres de ellas son:\n",
    "        </p>\n",
    "        <ol style=\"text-align: left; font-size: 18px; color: #002060;\">\n",
    "            <li style=\"margin: 20px 0;\"><strong>Método de la energía acumulada</strong>: En este método, se calcula la cantidad total de energía contenida en los valores singulares y se selecciona un número k de valores singulares que capturen una cierta fracción de esta energía total. Por ejemplo, se puede seleccionar el número de valores singulares que capturen el 90% de la energía total.</li>\n",
    "            <li style=\"margin: 20px 0;\"><strong>Método de la tasa de cambio de los valores singulares</strong>: En este método, se analiza la tasa de cambio de los valores singulares. Se selecciona un número k de valores singulares tal que el cambio en los valores singulares después del valor k es relativamente pequeño. Esto se hace para asegurarse de que se están seleccionando los valores singulares más significativos.</li>\n",
    "            <li style=\"margin: 20px 0;\"><strong>Método de la validación cruzada</strong>: En este método, se divide el conjunto de datos en dos partes: un conjunto de entrenamiento y un conjunto de prueba. Se entrena el modelo con diferentes valores de k y se evalúa el rendimiento del modelo en el conjunto de prueba para cada valor de k. Se selecciona el valor de k que produce el mejor rendimiento en el conjunto de prueba.</li>\n",
    "        </ol>\n",
    "        <h2 style=\"color: #f47b4c; margin-top: 100px;\">Ahora es tu turno</h2>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tools\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = tools.read_config_data()\n",
    "\n",
    "dtypes_articles = configuration.get(\"DTYPES_ARTICLES\")\n",
    "dtypes_articles = {\n",
    "    key: eval(value) if value.startswith(\"np\") else value for key, value in dtypes_articles.items()\n",
    "}\n",
    "\n",
    "path_articles = \"./recursos/datos/articles.csv\"\n",
    "articles = pd.read_csv(path_articles, dtype=dtypes_articles)\n",
    "content_columns_all = [\n",
    "    \"product_type_no\", \"graphical_appearance_no\", \"colour_group_code\", \"index_group_no\", \"index_code\", \"section_no\", \"garment_group_no\"\n",
    "]\n",
    "content_columns = [\n",
    "    content_columns_all[0], content_columns_all[1], \n",
    "    content_columns_all[2], content_columns_all[3]\n",
    "]\n",
    "articles_content = articles[[\"article_id\", *content_columns]]\n",
    "for cc in content_columns:\n",
    "    articles_content[cc] = articles_content[cc].astype(str)\n",
    "articles_content_ohe = pd.get_dummies(articles_content, columns=content_columns)\n",
    "articles_content_ohe = articles_content_ohe.set_index(\"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba2f67-a537-44d9-bfa4-0c6f130acc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_small_train = pd.read_csv(\n",
    "    \"./recursos/datos/transactions_small_train.csv\", \n",
    "    dtype={\n",
    "        \"cid\": str, \n",
    "        \"article_id\": str\n",
    "    }\n",
    ")\n",
    "transactions_small_test = pd.read_csv(\n",
    "    \"./recursos/datos/transactions_small_test.csv\", \n",
    "    dtype={\n",
    "        \"cid\": str, \n",
    "        \"article_id\": str, \n",
    "        \"interested\": int\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e9509-568a-4c1e-b56c-33f49eefd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a transformar los datos de entrenamiento en su forma \n",
    "# de matriz de interacción.\n",
    "user_item_matrix = pd.pivot_table(\n",
    "    data=transactions_small_train, \n",
    "    columns=\"article_id\", \n",
    "    index=\"cid\", \n",
    "    aggfunc=lambda _: 1,  # <-- Esto se añade para que en las celdas aparezca un 1.\n",
    "    fill_value=0\n",
    ")\n",
    "user_item_matrix = user_item_matrix.astype(float)\n",
    "user_item_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3890f1d-bd88-442a-8c5a-c7f84360399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de entrar a ver recomendaciones vamos a ver el espacio latente de variables\n",
    "# que vamos a implementar. En la implementación del SVD de scikit-learn solo nos permite\n",
    "# como máximo un número k que sea el mínimo entre el número de columnas y el número de\n",
    "# registros de la matriz user-item. Es por ello que vamos a aprovechar el máximo para ver\n",
    "# cuanto impactan los valores singulares.\n",
    "svd = TruncatedSVD(n_components=user_item_matrix.shape[1] - 1, algorithm=\"arpack\", tol=0)\n",
    "svd.fit(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e8301-f791-4fa7-998a-17b8a1ba5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La matriz u se calcula de la siguiente manera\n",
    "u = svd.transform(user_item_matrix)\n",
    "print(f\"La matriz u tiene {u.shape[0]} filas y {u.shape[1]} columnas.\")\n",
    "\n",
    "# La matriz sigma se obtiene de la siguiente manera\n",
    "sigma = svd.singular_values_\n",
    "print(f\"La matriz $\\\\Sigma$ tiene {sigma.shape[0]} valores singulares.\")\n",
    "\n",
    "# La matriz v se obtiene de la siguiente manera\n",
    "v = svd.components_\n",
    "print(f\"La matriz v tiene {v.shape[0]} filas y {v.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38872678-859c-48c7-b99e-fb948df067b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver cuánto contribuye cada característica al total de ellas.\n",
    "# Se observa que a medida que aumenta el número de dimensiones latentes\n",
    "# estas impactan menos en el total.\n",
    "sigma_pct = sigma / sigma.sum()\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.plot(sigma_pct)\n",
    "plt.title(\"Influencia de los valores singulares de $\\\\Sigma$\")\n",
    "plt.xlabel(\"Dimensión del espacio latente\")\n",
    "plt.ylabel(\"Importancia de la dimensión\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263e187-a424-47be-9f07-9dcba796b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observa que a medida que aumenta el número de dimensiones latentes\n",
    "# estas explican el sumatorio total de importancia. Siendo máximo cuando\n",
    "# se usan todas las dimensiones\n",
    "sigma_pct_acum = np.cumsum(sigma_pct)\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.plot(sigma_pct_acum)\n",
    "plt.title(\"Influencia de los valores singulares de $\\\\Sigma$\")\n",
    "plt.xlabel(\"Dimensión del espacio latente\")\n",
    "plt.ylabel(\"Importancia acumulada\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397207f-18f1-44cd-a97f-d5076c54ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuando se calcula el porcentaje que añade una nueva variable,\n",
    "# a la explicabilidad de los valores singulares previamente\n",
    "# existentes, se obtiene que a medida que se añaden variables\n",
    "# estas añaden cada vez menos información.\n",
    "diff_sigma_pct_acum = np.diff(sigma_pct_acum)\n",
    "growth = diff_sigma_pct_acum / sigma_pct_acum[:-1]\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.plot(growth)\n",
    "plt.title(\"Influencia de los valores singulares de $\\\\Sigma$\")\n",
    "plt.xlabel(\"Dimensión del espacio latente\")\n",
    "plt.ylabel(\"Ratio de crecimiento\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4fa33-1264-415b-91a9-1c749336cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT-CODE\n",
    "\n",
    "# Con la información de las gráficas anteriores obten las matrices SVD para un\n",
    "# espacio latente menor.\n",
    "n_latent = \n",
    "svd = \n",
    "u = \n",
    "sigma = \n",
    "v = \n",
    "print(f\"La matriz u tiene {u.shape[0]} filas y {u.shape[1]} columnas.\")\n",
    "print(f\"La matriz sigma tiene {sigma.shape[0]} valores singulares.\")\n",
    "print(f\"La matriz v tiene {v.shape[0]} filas y {v.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d1aac-0a84-445a-bc9f-d217f41f70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT-CODE\n",
    "\n",
    "def get_top_n_similarities(user_latent: pd.DataFrame, cid: str, n: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"Get the top N similar users for a given user.\n",
    "    \n",
    "    Apply the cosine similarity to calc similarities.\n",
    "    \n",
    "    :param user_latent: User latent matrix.\n",
    "    :param cid: Given user to calc the similarities.\n",
    "    :param n: Top n users to use as similars. By default is 50.\n",
    "    :return: Dataframe with the top n users similar to cid using\n",
    "        cosine metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # La funcion pairwise_distances permite calcular diferentes distancias\n",
    "    # en este caso la distancia del coseno. Esta función sin embargo no devuelve\n",
    "    # un resultado de similaridad, si no de des-similaridad, es por ello que\n",
    "    # es necesario hacer 1 - distancia del coseno.\n",
    "\n",
    "    \n",
    "    # Transforma en dataframe los resultados. Y elimina la similaridad con\n",
    "    # su propio usuario.\n",
    "\n",
    "    \n",
    "    # Para usar el método pandas.nlargest es necesario que el formato del dataframe\n",
    "    # sea column-wise y no row-wise. Por eso hay que calcularlo sobre la traspuesta.\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b5571-5905-4e10-aa59-c0044c29c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT-CODE\n",
    "\n",
    "# Tras haber modificado la función get_top_n_similarities primero es necesario\n",
    "# transformar la matriz u y v en un dataframe.\n",
    "df_u = \n",
    "df_v = \n",
    "# Aplica la función ahora sobre un cid específico.\n",
    "top_sims = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d65fb5-2189-44ac-9783-4f24b3c4d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT-CODE\n",
    "\n",
    "def get_top_k_recommendations(\n",
    "    user_item: pd.DataFrame,\n",
    "    user_latent: pd.DataFrame,\n",
    "    item_latent: pd.DataFrame,\n",
    "    similarities: pd.DataFrame,\n",
    "    cid: str,\n",
    "    k: int = 5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Get top k article recommendations for a given user.\n",
    "    \n",
    "    :param user_item: Interaction matrix.\n",
    "    :param user_latent: User latent matrix.\n",
    "    :param item_latent: Item latent matrix.\n",
    "    :param similarities: Dataframe with the top n users similar to cid using\n",
    "        cosine metrics.\n",
    "    :param cid: Given user to calc the similarities.\n",
    "    :param k: Top k recommendations for the user. By default is 5.\n",
    "    :return: Dataframe with k recommendation for the user.\n",
    "    \"\"\"\n",
    "    # Filtramos los usuarios similares de la matriz de usuarios latente.\n",
    "\n",
    "    \n",
    "    # Aprovechamos que la multiplicación de las matrices u y v dan los ratings\n",
    "    # para cada usuario. Y lo transformamos en un dataframe.\n",
    "\n",
    "    \n",
    "    # Ponderamos los ratings por el factor de similaridad.\n",
    "\n",
    "    \n",
    "    \n",
    "    # Eliminamos los productos que el usuario ya ha comprado\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90757f0-b998-4c9a-b945-b97e3ca6468c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STUDENT-CODE\n",
    "\n",
    "# Obten las recomendaciones para un usuario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31306b89-a697-4cbc-8b75-0312f564f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT-CODE\n",
    "\n",
    "# Ahora vamos a ejecutar para todos los usuarios de test sobre los cuales vamos a\n",
    "# calcular las métricas\n",
    "\n",
    "dfs = []\n",
    "for cid in tqdm(transactions_small_test[\"cid\"].unique()):\n",
    "    top_sims = \n",
    "    recs = \n",
    "    recs = recs.reset_index(drop=False, names=\"article_id\")\n",
    "    recs[\"cid\"] = cid\n",
    "    dfs.append(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33623425-0d63-4c33-a2e5-ef93f9eaad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.get_metrics(\n",
    "    name=\"CF-SVD-UserBased\", recommendations=pd.concat(dfs), sort_column=\"rating\",\n",
    "    true_labels=transactions_small_test, articles_df=articles_content_ohe\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74511b98",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #f47b4c; margin-top: 25px;\"> Conclusión</h2>\n",
    "<p style=\"font-size: 18px; color: #002060;\">\n",
    "    Estos métodos tienen ventajas respecto a los <em>memory-based</em>:\n",
    "<ul style=\"text-align: left; font-size: 18px; color: #002060;\">\n",
    "        <li style=\"margin: 20px 0;\"><strong>Eficiencia</strong>: menos requisitos de espacio de memoria y menor complejidad computacional.</li>\n",
    "        <li style=\"margin: 20px 0;\"><strong>Velocidad de entrenamiento y predicción</strong>: los sistemas basados ​​en modelos suelen ser mucho más rápidos en la fase de preprocesamiento de la construcción del modelo entrenado.</li>\n",
    "        <li style=\"margin: 20px 0;\"><strong>Sobreajuste</strong>: los sistemas basados en modelos presentan menor sobreajuste que los basados en memoria. Además permiten incluir métodos de regularización.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9634b3da602d5469ebed6cb686a14de7e88f55af7e918366dbf4f55476a71a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
